# Default values for sentry.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
serverReplicaCount: 1
workerReplicaCount: 1

#  SENTRY_FILESTORE_DIR
#
#secretKey: $(docker run --rm sentry config generate-secret-key)
#emailHost:
#serverEmail: '"Sentry" <root@localhost>'
#singleOrganization: false
#githubAppId:
#githubApiSecret:
#useSsl: false
#
#extraEnvVars:
#  e.g.
#  GITHUB_BASE_DOMAIN: github.example.com
#  GITHUB_API_DOMAIN: api.github.example.com
#
# initial user:
# adminEmail:
# adminPassword:
# Generate with: python -c 'import sys,uuid; sys.stdout.write(uuid.uuid4().hex+ uuid.uuid4().hex)
# adminToken:
organizationName: Monsoon
organizationSlug: monsoon
image:
  sentry:
    repository: sentry
    tag: 23.8.0-r1
    pullPolicy: IfNotPresent
  snuba:
    repository: getsentry/snuba
    tag: 23.8.0
    pullPolicy: IfNotPresent
  relay:
    repository: getsentry/relay
    tag: 23.8.0
    pullPolicy: IfNotPresent
  symbolicator:
    repository: getsentry/symbolicator
    tag: 23.8.0
    pullPolicy: IfNotPresent

service:
  name: sentry
  type: ClusterIP
  externalPort: 80
  internalPort: 9000
pruning_time: '0315'

owner-info:
  support-group: identity
  service: sentry
  maintainers:
    - Rajiv Mucheli
    - Olaf Heydorn
  helm-chart-url: https://github.com/sapcc/helm-charts/tree/master/system/sentry

ingress:
  enabled: false
#  host:
#  tls_crt:
#  tls_key:

rbac:
  create: true

memcached:
  memoryLimit: "2048"
  args:
    - "memcached"
    - "-u memcached"
  alerts:
    support_group: identity

operator:
  #sentryEndpoint: https://sentry.$region.cloud.sap/api/0/
  enabled: false
  image:
    repository: kube-sentry
    tag: 0.3.0
    pullPolicy: IfNotPresent

postgresql:
  postgresDatabase: sentry
  persistence:
    enabled: true
    accessMode: ReadWriteMany
    size: 50Gi
  resources:
    requests:
      memory: 10Gi
      cpu: 4
    limits:
      memory: 10Gi
      cpu: 4
  enabled: true
  auth:
    database: sentry
  replication:
    enabled: false
    readReplicas: 2
    synchronousCommit: "on"
    numSynchronousReplicas: 1
    applicationName: sentry
  ## Use this to enable an extra service account
  # serviceAccount:
  #   enabled: false

redis:
  # redisPassword:
  persistence:
    enabled: true
    accessMode: ReadWriteMany
    size: 10Gi
  resources:
    requests:
      memory: 5Gi
      cpu: 2
    limits:
      memory: 10Gi
      cpu: 2

sentry:
  resources:
    requests:
      memory: 5Gi
      cpu: 4
    limits:
      memory: 10Gi
      cpu: 4
  postProcessForward:
    commitBatchSize: 1

  cleanup:
    successfulJobsHistoryLimit: 5
    failedJobsHistoryLimit: 5
    activeDeadlineSeconds: 100
    concurrencyPolicy: Allow
    concurrency: 1
    enabled: false
    schedule: "0 0 * * *"
    days: 90
    # securityContext: {}
    # containerSecurityContext: {}
    sidecars: []
    volumes: []
    # volumeMounts: []
    serviceAccount: {}

  ingestReplayRecordings:
    autoscaling:
      enabled: false

  ingestOccurrences:
    autoscaling:
      enabled: false

  ingestMonitors:
    autoscaling:
      enabled: false

  ingestMetricsConsumerRh:
    autoscaling:
      enabled: false

  ingestMetricsConsumerPerf:
    autoscaling:
      enabled: false

  ingestConsumer:
    autoscaling:
      enabled: false

  features:
    orgSubdomains: false
    vstsLimitedScopes: true
    enableProfiling: false

serviceAccount:
  annotations: {}
  enabled: true
  name: "sentry"
  automountServiceAccountToken: true

# Deploy Sentry Prometheus alerts.
alerts:
  enabled: true
  # Name of the Prometheus to which the alerts should be assigned to.
  prometheus: openstack

pgbackup:
  database:
    name: sentry
  alerts:
    support_group: foundation

pgmetrics:
  db_name: sentry
  alerts:
    large_database_size_enabled: false
    support_group: foundation

  customMetrics:
    sentry_unresolved_issues:
      query: >
        SELECT o.slug AS organization, p.slug AS project, COUNT(*) FROM sentry_groupedmessage gm
          JOIN sentry_project p ON gm.project_id = p.id
          JOIN sentry_organization o ON p.organization_id = o.id
         WHERE gm.status = 0
         GROUP BY o.slug, p.slug
      metrics:
        - organization: {usage: LABEL, description: "Sentry organization"}
        - project:      {usage: LABEL, description: "Sentry project"}
        - gauge:        {usage: GAUGE, description: "Number of unresolved issues in project"}

    sentry_unresolved_issues_nova:
      query: >
        SELECT o.slug AS organization, p.slug AS project, message, COUNT(*) FROM sentry_groupedmessage gm
          JOIN sentry_project p ON gm.project_id = p.id
          JOIN sentry_organization o ON p.organization_id = o.id
         WHERE gm.status = 0 AND p.slug = 'nova'
         GROUP BY o.slug, p.slug, message
      metrics:
        - organization: {usage: LABEL, description: "Sentry organization"}
        - project:      {usage: LABEL, description: "Sentry project"}
        - message:      {usage: LABEL, description: "Issue message"}
        - gauge:        {usage: GAUGE, description: "Number of unresolved issues in project"}

probe:
  enabled: false

# enable when Sentry version is upgraded, also validate if GEOIP_PATH_MMDB is configured.
databaseUpgrade:
  enabled: false

# sentry-sentry-tls is used, keeping the config for future reference.
secretIngress:
  tls_crt:
    enabled: false

config:
  # No YAML Extension Config Given
  configYml: {}
  sentryConfPy: |
    # No Python Extension Config Given
  snubaSettingsPy: |
    # No Python Extension Config Given
  relay: |
    # No YAML relay config given
  web:
    httpKeepalive: 15

kafka:
  enabled: true
  service:
    ports:
      client: 9092
  # provisioning:
  #   enabled: true
  #   # Topic list is based on files below.
  #   # - https://github.com/getsentry/snuba/blob/master/snuba/utils/streams/topics.py
  #   # - https://github.com/getsentry/self-hosted/blob/master/install/create-kafka-topics.sh#L6
  #   # Note that snuba component might fail if you set `hooks.snubaInit.kafka.enabled` to `false` and remove the topics from this default topic list.
  #   topics:
  #     - name: events
  #       config:
  #         "message.timestamp.type": LogAppendTime
  #     - name: event-replacements
  #     - name: snuba-commit-log
  #     - name: cdc
  #     - name: transactions
  #       config:
  #         "message.timestamp.type": LogAppendTime
  #     - name: snuba-transactions-commit-log
  #     - name: snuba-metrics
  #       config:
  #         "message.timestamp.type": LogAppendTime
  #     - name: outcomes
  #     - name: ingest-sessions
  #     - name: snuba-sessions-commit-log
  #     - name: snuba-metrics-commit-log
  #     - name: scheduled-subscriptions-events
  #     - name: scheduled-subscriptions-transactions
  #     - name: scheduled-subscriptions-sessions
  #     - name: scheduled-subscriptions-metrics
  #     - name: scheduled-subscriptions-generic-metrics-sets
  #     - name: scheduled-subscriptions-generic-metrics-distributions
  #     - name: scheduled-subscriptions-generic-metrics-counters
  #     - name: events-subscription-results
  #     - name: transactions-subscription-results
  #     - name: sessions-subscription-results
  #     - name: metrics-subscription-results
  #     - name: generic-metrics-subscription-results
  #     - name: snuba-queries
  #       config:
  #         "message.timestamp.type": LogAppendTime
  #     - name: processed-profiles
  #       config:
  #         "message.timestamp.type": LogAppendTime
  #     - name: profiles-call-tree
  #     - name: ingest-replay-events
  #       config:
  #         "message.timestamp.type": LogAppendTime
  #         "max.message.bytes": "15000000"
  #     - name: snuba-generic-metrics
  #       config:
  #         "message.timestamp.type": LogAppendTime
  #     - name: snuba-generic-metrics-sets-commit-log
  #     - name: snuba-generic-metrics-distributions-commit-log
  #     - name: snuba-generic-metrics-counters-commit-log
  #     - name: generic-events
  #       config:
  #         "message.timestamp.type": LogAppendTime
  #     - name: snuba-generic-events-commit-log
  #     - name: group-attributes
  #       config:
  #         "message.timestamp.type": LogAppendTime
  #     - name: snuba-attribution
  #     - name: snuba-dead-letter-metrics
  #     - name: snuba-dead-letter-metrics-sets
  #     - name: snuba-dead-letter-metrics-counters
  #     - name: snuba-dead-letter-metrics-distributions
  #     - name: snuba-dead-letter-sessions
  #     - name: snuba-dead-letter-generic-metrics
  #     - name: snuba-dead-letter-replays
  #     - name: snuba-dead-letter-generic-events
  #     - name: snuba-dead-letter-querylog
  #     - name: snuba-dead-letter-group-attributes
  #     - name: ingest-attachments
  #     - name: ingest-transactions
  #     - name: ingest-events
  #     - name: ingest-replay-recordings
  #     - name: ingest-metrics
  #     - name: ingest-performance-metrics
  #     - name: ingest-monitors
  #     - name: profiles
  #     - name: ingest-occurrences

externalKafka:
  ## Hostname or ip address of external kafka
  ##
  # host: "kafka-confluent"
  port: 9092

symbolicator:
  enabled: false
  api:
    config: |-
      # See: https://getsentry.github.io/symbolicator/#configuration
      cache_dir: "/data"
      bind: "0.0.0.0:3021"
      logging:
        level: "warn"
      metrics:
        statsd: null
        prefix: "symbolicator"
      sentry_dsn: null
      connect_to_reserved_ips: true
      # caches:
      #   downloaded:
      #     max_unused_for: 1w
      #     retry_misses_after: 5m
      #     retry_malformed_after: 5m
      #   derived:
      #     max_unused_for: 1w
      #     retry_misses_after: 5m
      #     retry_malformed_after: 5m
      #   diagnostics:
      #     retention: 1w

metrics:
  enabled: false
  serviceMonitor:
    enabled: false

snuba:
  api:
    probeInitialDelaySeconds: 10
  transactionsConsumer:
    replicas: 1

relay:
  probeInitialDelaySeconds: 10
  autoscaling:
    enabled: false

## This value is only used when clickhouse.enabled is set to false
##
externalClickhouse:
  ## Hostname or ip address of external clickhouse
  ##
  host: "clickhouse"
  tcpPort: 9000
  httpPort: 8123
  username: default
  password: ""
  database: default
  ## Cluster name, can be found in config
  ## (https://clickhouse.tech/docs/en/operations/server-configuration-parameters/settings/#server-settings-remote-servers)
  ## or by executing `select * from system.clusters`
  ##
  clusterName: test_shard_localhost

system:
  ## be sure to include the scheme on the url, for example: "https://sentry.example.com"
  url: ""
  adminEmail: ""
  ## This should only be used if you’re installing Sentry behind your company’s firewall.
  public: false
  ## This will generate one for you (it's must be given upon updates)
  # secretKey: "xx"

clickhouse:
  enabled: false
  ingress:
    enabled: false
  persistentVolumeClaim:
    enabled: false
    dataPersistentVolume:
      enabled: false
      accessModes:
      - "ReadWriteOnce"
      storage: "30Gi"
    ## Clickhouse logs volume
    logsPersistentVolume:
      enabled: false
      accessModes:
      - "ReadWriteOnce"
      storage: "50Gi"
  configmap:
    remote_servers:
      internal_replication: true
      replica:
        backup:
          enabled: false
    logger:
      path: "/var/log/clickhouse-server"
      level: "trace"
      size: "1000M"
      count: "10"
      stdoutLogsEnabled: false
    ##
    ## Data compression settings.
    # min_part_size – The minimum size of a table part.
    # min_part_size_ratio – The ratio of the minimum size of a table part to the full size of the table.
    # method – Compression method. Acceptable values ​: lz4 or zstd(experimental).
    compression:
      enabled: false
      cases:
      - min_part_size: "10000000000"
        min_part_size_ratio: "0.01"
        method: "zstd"
  clickhouse:
    imageVersion: "20.8.9.6"
    configmap:
      remote_servers:
        internal_replication: true
        replica:
          backup:
            enabled: false
      users:
        enabled: false
        user:
        # the first user will be used if enabled
        - name: default
          config:
            password: ""
            networks:
            - ::/0
            profile: default
            quota: default

  metrics:
    enabled: false
    serviceMonitor:
      enabled: false

  livenessProbe:
    enabled: true
    initialDelaySeconds: "30"
    periodSeconds: "30"
    timeoutSeconds: "5"
    failureThreshold: "3"
    successThreshold: "1"
  ## Periodic probe of container service readiness. Container will be removed from service endpoints if the probe fails. Cannot be updated.
  ## More info: https://kubernetes.io/docs/concepts/workloads/pods/pod-lifecycle#container-probes
  readinessProbe:
    enabled: true
    initialDelaySeconds: "30"
    periodSeconds: "30"
    timeoutSeconds: "5"
    failureThreshold: "3"
    successThreshold: "1"
  ## volumeClaimTemplates is a list of claims that pods are allowed to reference.
  ## The StatefulSet controller is responsible for mapping network identities to claims in a way that maintains the identity of a pod.
  ## Every claim in this list must have at least one matching (by name) volumeMount in one container in the template.
  ## A claim in this list takes precedence over any volumes in the template, with the same name.


hooks:
  enabled: true
  removeOnSuccess: true
  activeDeadlineSeconds: 100
  shareProcessNamespace: false
  dbCheck:
    image:
      repository: subfuzion/netcat
      tag: latest
      pullPolicy: IfNotPresent
      imagePullSecrets: []
    env: []
    podAnnotations: {}
    resources:
      limits:
        memory: 64Mi
      requests:
        cpu: 100m
        memory: 64Mi
  dbInit:
    env: []
    podAnnotations: {}
    resources:
      limits:
        memory: 2048Mi
      requests:
        cpu: 300m
        memory: 2048Mi
  snubaInit:
    # As snubaInit doesn't support configuring partition and replication factor, you can disable snubaInit's kafka topic creation by setting `kafka.enabled` to `false`,
    # and create the topics using `kafka.provisioning.topics` with the desired partition and replication factor.
    # Note that when you set `kafka.enabled` to `false`, snuba component might fail to start if newly added topics are not created by `kafka.provisioning`.
    kafka:
      enabled: true
    podAnnotations: {}
    resources:
      limits:
        cpu: 2000m
        memory: 1Gi
      requests:
        cpu: 700m
  snubaMigrate: {}

# https://github.com/settings/apps (Create a Github App)
github: {}
# github:
#   appId: "xxxx"
#   appName: MyAppName
#   clientId: "xxxxx"
#   clientSecret: "xxxxx"
#   privateKey: "-----BEGIN RSA PRIVATE KEY-----\nMIIEpA" !!!! Don't forget a trailing \n
#   webhookSecret:  "xxxxx"
#
#   Note: if you use `existingSecret`, all above `clientId`, `clientSecret`, `privateKey`, `webhookSecret`
#   params would be ignored, because chart will suppose that they are stored in `existingSecret`. So you
#   must define all required keys and set it at least to empty strings if they are not needed in `existingSecret`
#   secret (client-id, client-secret, webhook-secret, private-key)
#
#   existingSecret: "xxxxx"
#   existingSecretPrivateKeyKey: ""     # by default "private-key"
#   existingSecretWebhookSecretKey: ""  # by default "webhook-secret"
#   existingSecretClientIdKey: ""       # by default "client-id"
#   existingSecretClientSecretKey: ""   # by default "client-secret"
#
#   Reference -> https://docs.sentry.io/product/integrations/source-code-mgmt/github/

filestore:
  # Set to one of filesystem, gcs or s3 as supported by Sentry.
  backend: filesystem

  filesystem:
    path: /var/lib/sentry/files

    ## Enable persistence using Persistent Volume Claims
    ## ref: http://kubernetes.io/docs/user-guide/persistent-volumes/
    ##
    persistence:
      enabled: true
      ## database data Persistent Volume Storage Class
      ## If defined, storageClassName: <storageClass>
      ## If set to "-", storageClassName: "", which disables dynamic provisioning
      ## If undefined (the default) or set to null, no storageClassName spec is
      ##   set, choosing the default provisioner.  (gp2 on AWS, standard on
      ##   GKE, AWS & OpenStack)
      ##
      # storageClass: "-"
      accessMode: ReadWriteOnce
      size: 10Gi

      ## Whether to mount the persistent volume to the Sentry worker and
      ## cron deployments. This setting needs to be enabled for some advanced
      ## Sentry features, such as private source maps. If you disable this
      ## setting, the Sentry workers will not have access to artifacts you upload
      ## through the web deployment.
      ## Please note that you may need to change your accessMode to ReadWriteMany
      ## if you plan on having the web, worker and cron deployments run on
      ## different nodes.
      persistentWorkers: false

      ## If existingClaim is specified, no PVC will be created and this claim will
      ## be used
      existingClaim: ""

sourcemaps:
  enabled: false

rabbitmq:
  ## If disabled, Redis will be used instead as the broker.
  enabled: true
  vhost: /
  clustering:
    forceBoot: true
    rebalance: true
  replicaCount: 3
  auth:
    erlangCookie: pHgpy3Q6adTskzAT6bLHCFqFTF7lMxhA
    username: guest
    password: guest
  nameOverride: ""

  pdb:
    create: true
  persistence:
    enabled: true
  resources: {}
  memoryHighWatermark: {}
    # enabled: true
    # type: relative
    # value: 0.4

  extraSecrets:
    load-definition:
      load_definition.json: |
        {
          "users": [
            {
              "name": "{{ .Values.auth.username }}",
              "password": "{{ .Values.auth.password }}",
              "tags": "administrator"
            }
          ],
          "permissions": [{
            "user": "{{ .Values.auth.username }}",
            "vhost": "/",
            "configure": ".*",
            "write": ".*",
            "read": ".*"
          }],
          "policies": [
            {
              "name": "ha-all",
              "pattern": ".*",
              "vhost": "/",
              "definition": {
                "ha-mode": "all",
                "ha-sync-mode": "automatic",
                "ha-sync-batch-size": 1
              }
            }
          ],
          "vhosts": [
            {
              "name": "/"
            }
          ]
        }
  loadDefinition:
    enabled: true
    existingSecret: load-definition
  extraConfiguration: |
    load_definitions = /app/load_definition.json
  ## Use this to enable an extra service account
  # serviceAccount:
  #   create: false
  #   name: rabbitmq

auth:
  register: true

tabix:
  ##
  ## Enable Tabix
  enabled: false
